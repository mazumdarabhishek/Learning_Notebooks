{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification of Movie Reviews using Transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"data\\train.tsv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['SentenceId'], keep= 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId                                             Phrase  \\\n",
       "0           1           1  A series of escapades demonstrating the adage ...   \n",
       "63         64           2  This quiet , introspective and entertaining in...   \n",
       "81         82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "116       117           4  A positively thrilling combination of ethnogra...   \n",
       "156       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "     Sentiment  \n",
       "0            1  \n",
       "63           4  \n",
       "81           1  \n",
       "116          3  \n",
       "156          1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbec5792e5143b58c076a453d6c5e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\NLP\\nlp_env\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abhishek.mazumdar\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6706610a8d9c4cce80b232d4ae29e9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148c397fdaee4a758f789d0ed6e8e5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\n",
    "    df['Phrase'].to_list(),\n",
    "    max_length = 512,\n",
    "    truncation = True, \n",
    "    padding = 'max_length',\n",
    "    add_special_tokens = True,\n",
    "    return_tensors = 'np'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8529"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_labels = np.zeros(shape=(df.shape[0], labels.max() + 1))\n",
    "empty_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_labels[np.arange(df.shape[0]), labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "onHotLabels = empty_labels\n",
    "del empty_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onHotLabels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids = tokens['input_ids']\n",
    "Masks = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((Ids, Masks, onHotLabels))\n",
    "dataset.take(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently each sample of dataset is a tuple of (Ids, Masks, onHotLabels). The required input schema for model is (<input_data>, <output_data>). Hence, we need to convert ({Ids, Masks}, onHotLabels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_map(input_ids, attention_mask, labels):\n",
    "    return{'input_ids': input_ids, 'attention_mask': attention_mask}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(helper_map)\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder = True)\n",
    "\n",
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479.75625"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = (Ids.shape[0] / batch_size ) * 0.9\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.take(round(train_size))\n",
    "val_data = dataset.skip(round(train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.element_spec == val_data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None),\n",
       "  'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abhishek.mazumdar\\AppData\\Local\\Temp\\ipykernel_27376\\3110436677.py:1: save (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.save(...)` instead.\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_data, 'train')\n",
    "tf.data.experimental.save(val_data, 'val')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhishek.mazumdar\\.conda\\envs\\transformerEnv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|██████████| 570/570 [00:00<00:00, 507kB/s]\n",
      "Downloading: 100%|██████████| 527M/527M [00:40<00:00, 12.9MB/s]   \n",
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  108310272 \n",
      "=================================================================\n",
      "Total params: 108,310,272\n",
      "Trainable params: 108,310,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel\n",
    "\n",
    "bert = TFAutoModel.from_pretrained('bert-base-cased')\n",
    "\n",
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.keras.layers.Input(shape=(512,), name = 'input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape= (512,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# access the embeddings at the final layer. Convert the 3D tensors to 2D\n",
    "embeddings = bert.bert(input_ids, attention_mask= mask)[1]\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         787456      bert[1][1]                       \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            5125        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,102,853\n",
      "Trainable params: 792,581\n",
      "Non-trainable params: 108,310,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs = [input_ids, mask], outputs = y)\n",
    "model.layers[2].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abhishek.mazumdar\\.conda\\envs\\transformerEnv\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=1e-5, decay=1e-6)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_spec = ({'input_ids': tf.TensorSpec(shape=(16, 512), dtype=tf.int32, name=None),\n",
    "                'attention_mask': tf.TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)},\n",
    "                tf.TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))\n",
    "\n",
    "train_data = tf.data.experimental.load('train', element_spec = element_spec)\n",
    "val_data = tf.data.experimental.load('val', element_spec = element_spec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  2/480 [..............................] - ETA: 2:08:02 - loss: 1.5219 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformerEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d80bf2fadab20c34f8e9f546dac610b12162f7d0cf18029659da28df4e274d5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
